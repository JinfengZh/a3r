{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neu import NeuMF\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "THREADS = 16\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "loss_func = torch.nn.MSELoss()\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "mlp_factors = 8\n",
    "gmf_factors = 32 \n",
    "layers = [64,32,16,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_predictions(true_ratings, predicted_ratings):\n",
    "    assert len(true_ratings) == len(predicted_ratings)\n",
    "    binary_true_ratings = []\n",
    "    binary_predicted_ratings = []\n",
    "\n",
    "    for i in range(len(true_ratings)):\n",
    "        if true_ratings[i] >= 3:\n",
    "            binary_true_ratings.append(1)\n",
    "        else:\n",
    "            binary_true_ratings.append(0)\n",
    "\n",
    "        if predicted_ratings[i] >= 3:\n",
    "            binary_predicted_ratings.append(1)\n",
    "        else:\n",
    "            binary_predicted_ratings.append(0)\n",
    "\n",
    "    return precision_score(binary_true_ratings, binary_predicted_ratings), recall_score(binary_true_ratings, binary_predicted_ratings), f1_score(binary_true_ratings, binary_predicted_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_accuracy_int(ratings, predictions):\n",
    "    ratings = ratings.cpu().detach().numpy()\n",
    "    predictions = predictions.cpu().detach().numpy()\n",
    "    total_nr = len(ratings)\n",
    "    total_pred = 0\n",
    "    for i in range(total_nr):\n",
    "        (true_rating, pred_rating) = ratings[i], predictions[i]\n",
    "        if round(pred_rating) >= int(true_rating)-1 and round(pred_rating) <= int(true_rating)+1:\n",
    "            total_pred += 1\n",
    "\n",
    "    return float(total_pred)/total_nr\n",
    "\n",
    "\n",
    "def round_of_rating(number):\n",
    "    return round(number * 2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(data, model):\n",
    "    users_index = data.iloc[:, 0].values\n",
    "    users = torch.LongTensor(users_index).to(DEVICE)\n",
    "    items_index = data.iloc[:, 1].values\n",
    "    items = torch.LongTensor(items_index).to(DEVICE)\n",
    "    rating = torch.FloatTensor(data.iloc[:, 5].values).to(DEVICE)\n",
    "    prediction= model(users, items)\n",
    "    rmse = loss_func(prediction, rating)\n",
    "    mae = torch.nn.L1Loss()(prediction, rating)\n",
    "    \n",
    "    p,r,f = binary_predictions(rating, prediction)\n",
    "    accuracy = arg_accuracy_int(rating,prediction)\n",
    "    return rmse ** 0.5,mae,p,r,f, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "trainset = pd.read_csv('train.csv')\n",
    "testset = pd.read_csv('test.csv')\n",
    "trainset['user_rating'] = (trainset['user_rating'] + 1) * 2 + 1\n",
    "testset['user_rating'] = (testset['user_rating'] + 1) * 2 + 1\n",
    "def traite_train_test(df):\n",
    "    df['actors'] = df['actors'].apply(lambda x: json.loads(x))\n",
    "    df['director'] = df['director'].apply(lambda x: json.loads(x))\n",
    "    df['genre'] = df['genre'].apply(lambda x: json.loads(x))\n",
    "    return df\n",
    "trainset = traite_train_test(trainset)\n",
    "testset = traite_train_test(testset)\n",
    "hehe_test = trainset.copy()\n",
    "df_empty = testset.copy()\n",
    "df_empty['user_id'] = df_empty['user_id'].astype('int')\n",
    "df_empty['user_rating'] = df_empty['user_rating'].astype('float')\n",
    "df_empty['movie'] = df_empty['movie'].astype('int')\n",
    "hehe_test.index = range(len(hehe_test))\n",
    "df_empty.index = range(len(df_empty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hehe = pd.concat([hehe_test,df_empty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lr, mlp_factors,gmf_factors, layers, reg, batch_size, num_epochs, train, test):\n",
    "    model = NeuMF(n_users, n_items, mlp_factors,gmf_factors, layers).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=lr,weight_decay=reg)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=10, threshold_mode='abs',threshold = 0.005)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        t1 = time.time()\n",
    "        num_example = len(train)\n",
    "        indices = list(range(num_example))\n",
    "        for i in tqdm(range(0, num_example, batch_size)):\n",
    "            optimizer.zero_grad()\n",
    "            indexs = indices[i:min(i+batch_size, num_example)]\n",
    "            users_index = train.iloc[:, 0].loc[indexs].values\n",
    "            users = torch.LongTensor(users_index).to(DEVICE)\n",
    "            items_index = train.iloc[:, 1].loc[indexs].values\n",
    "            items = torch.LongTensor(items_index).to(DEVICE)\n",
    "            \n",
    "           \n",
    "            rating = torch.FloatTensor(\n",
    "                train.iloc[:, 5].loc[indexs].values).to(DEVICE)\n",
    "            prediction = model(\n",
    "                users, items)\n",
    "\n",
    "            err = loss_func(prediction, rating) \n",
    "            err.backward()\n",
    "            optimizer.step()\n",
    "        t2 = time.time()\n",
    "        #rmse, mae = RMSE(test, model)\n",
    "        \n",
    "        \n",
    "        rmse, mae, p, r, f, accuracy = RMSE(testset,model)\n",
    "        scheduler.step(rmse)\n",
    "        print(\"Learning rate: \", lr, \"Regulation: \", reg,\"Bath_size:\",batch_size)\n",
    "        print(\"RMSE: \", rmse, \"MAE: \", mae)\n",
    "        print(\"Accuracy: \", accuracy, \"Precision: \", p, \"Recall: \", r, \"F1 score: \", f)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = len(hehe['user_id'].value_counts())\n",
    "n_items = len(hehe['movie'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1207/1207 [00:32<00:00, 37.40it/s]\n",
      "  0%|          | 6/1207 [00:00<00:21, 55.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.002 Regulation:  0.0001 Bath_size: 128\n",
      "RMSE:  tensor(1.0072, grad_fn=<PowBackward0>) MAE:  tensor(0.8069, grad_fn=<L1LossBackward>)\n",
      "Accuracy:  0.8559405427801947 Precision:  0.8283694211224039 Recall:  0.9034507132759285 F1 score:  0.8642825308518649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1207/1207 [00:24<00:00, 49.26it/s]\n",
      "  0%|          | 6/1207 [00:00<00:22, 54.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.002 Regulation:  0.0001 Bath_size: 128\n",
      "RMSE:  tensor(0.9469, grad_fn=<PowBackward0>) MAE:  tensor(0.7505, grad_fn=<L1LossBackward>)\n",
      "Accuracy:  0.8826911124922312 Precision:  0.8702795403875836 Recall:  0.8152229790515358 F1 score:  0.8418520546127176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1207/1207 [00:23<00:00, 50.80it/s]\n",
      "  0%|          | 6/1207 [00:00<00:24, 49.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.002 Regulation:  0.0001 Bath_size: 128\n",
      "RMSE:  tensor(0.9307, grad_fn=<PowBackward0>) MAE:  tensor(0.7354, grad_fn=<L1LossBackward>)\n",
      "Accuracy:  0.8911850010358401 Precision:  0.8801288632421143 Recall:  0.7987726513301632 F1 score:  0.8374795775715417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1207/1207 [00:24<00:00, 50.01it/s]\n",
      "  0%|          | 6/1207 [00:00<00:22, 52.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.002 Regulation:  0.0001 Bath_size: 128\n",
      "RMSE:  tensor(0.9289, grad_fn=<PowBackward0>) MAE:  tensor(0.7333, grad_fn=<L1LossBackward>)\n",
      "Accuracy:  0.8923244251087632 Precision:  0.8806436716280062 Recall:  0.7965235830870068 F1 score:  0.8364740615773935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1207/1207 [00:27<00:00, 44.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.002 Regulation:  0.0001 Bath_size: 128\n",
      "RMSE:  tensor(0.9287, grad_fn=<PowBackward0>) MAE:  tensor(0.7327, grad_fn=<L1LossBackward>)\n",
      "Accuracy:  0.8919100890822457 Precision:  0.8805127476741709 Recall:  0.7967163603649916 F1 score:  0.8365212697770131\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "lr = 0.002\n",
    "reg = 1e-4\n",
    "batch_size = 128\n",
    "num_epochs = 5\n",
    "model_neumf = train(lr, mlp_factors,gmf_factors, layers, reg, batch_size, num_epochs, hehe_test,df_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = { 'model': model_neumf.state_dict()}   \n",
    "torch.save(state, 'model_neumf.pkl')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neu import MF\n",
    "mf_factors = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lr,mf_factors , reg, batch_size, num_epochs, train, test):\n",
    "    model = MF(n_users, n_items,mf_factors ).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=lr,weight_decay=reg)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=10, threshold_mode='abs',threshold = 0.005)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        t1 = time.time()\n",
    "        num_example = len(train)\n",
    "        indices = list(range(num_example))\n",
    "        for i in tqdm(range(0, num_example, batch_size)):\n",
    "            optimizer.zero_grad()\n",
    "            indexs = indices[i:min(i+batch_size, num_example)]\n",
    "            users_index = train.iloc[:, 0].loc[indexs].values\n",
    "            users = torch.LongTensor(users_index).to(DEVICE)\n",
    "            items_index = train.iloc[:, 1].loc[indexs].values\n",
    "            items = torch.LongTensor(items_index).to(DEVICE)\n",
    "            \n",
    "           \n",
    "            rating = torch.FloatTensor(\n",
    "                train.iloc[:, 5].loc[indexs].values).to(DEVICE)\n",
    "            prediction = model(\n",
    "                users, items)\n",
    "\n",
    "            err = loss_func(prediction, rating) \n",
    "            err.backward()\n",
    "            optimizer.step()\n",
    "        t2 = time.time()\n",
    "        #rmse, mae = RMSE(test, model)\n",
    "        \n",
    "        \n",
    "        rmse, mae, p, r, f, accuracy = RMSE(testset,model)\n",
    "        scheduler.step(rmse)\n",
    "        print(\"Learning rate: \", lr, \"Regulation: \", reg,\"Bath_size:\",batch_size)\n",
    "        print(\"RMSE: \", rmse, \"MAE: \", mae)\n",
    "        print(\"Accuracy: \", accuracy, \"Precision: \", p, \"Recall: \", r, \"F1 score: \", f)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mf = train(lr,mf_factors , reg, batch_size, num_epochs, hehe_test,df_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = { 'model': model_mf.state_dict()}   \n",
    "torch.save(state, 'model_mf.pkl')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
