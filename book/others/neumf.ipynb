{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neu import NeuMF\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "THREADS = 16\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "loss_func = torch.nn.MSELoss()\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "mlp_factors = 8\n",
    "gmf_factors = 32 \n",
    "layers = [64,32,16,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_predictions(true_ratings, predicted_ratings):\n",
    "    assert len(true_ratings) == len(predicted_ratings)\n",
    "    binary_true_ratings = []\n",
    "    binary_predicted_ratings = []\n",
    "\n",
    "    for i in range(len(true_ratings)):\n",
    "        if true_ratings[i] >= 3:\n",
    "            binary_true_ratings.append(1)\n",
    "        else:\n",
    "            binary_true_ratings.append(0)\n",
    "\n",
    "        if predicted_ratings[i] >= 3:\n",
    "            binary_predicted_ratings.append(1)\n",
    "        else:\n",
    "            binary_predicted_ratings.append(0)\n",
    "\n",
    "    return precision_score(binary_true_ratings, binary_predicted_ratings), recall_score(binary_true_ratings, binary_predicted_ratings), f1_score(binary_true_ratings, binary_predicted_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_accuracy_int(ratings, predictions):\n",
    "    ratings = ratings.cpu().detach().numpy()\n",
    "    predictions = predictions.cpu().detach().numpy()\n",
    "    total_nr = len(ratings)\n",
    "    total_pred = 0\n",
    "    for i in range(total_nr):\n",
    "        (true_rating, pred_rating) = ratings[i], predictions[i]\n",
    "        if round(pred_rating) >= int(true_rating)-1 and round(pred_rating) <= int(true_rating)+1:\n",
    "            total_pred += 1\n",
    "\n",
    "    return float(total_pred)/total_nr\n",
    "\n",
    "\n",
    "def round_of_rating(number):\n",
    "    return round(number * 2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(data, model):\n",
    "    users_index = data.iloc[:, 0].values\n",
    "    users = torch.LongTensor(users_index).to(DEVICE)\n",
    "    items_index = data.iloc[:, 1].values\n",
    "    items = torch.LongTensor(items_index).to(DEVICE)\n",
    "    rating = torch.FloatTensor(data.iloc[:, 4].values).to(DEVICE)\n",
    "    prediction= model(users, items)\n",
    "    rmse = loss_func(prediction, rating)\n",
    "    mae = torch.nn.L1Loss()(prediction, rating)\n",
    "    \n",
    "    p,r,f = binary_predictions(rating, prediction)\n",
    "    accuracy = arg_accuracy_int(rating,prediction)\n",
    "    return rmse ** 0.5,mae,p,r,f, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "trainset = pd.read_csv('train.csv')\n",
    "testset = pd.read_csv('test.csv')\n",
    "#trainset['user_rating'] = (trainset['user_rating'] + 1) * 2 + 1\n",
    "#testset['user_rating'] = (testset['user_rating'] + 1) * 2 + 1\n",
    "def traite_train_test(df):\n",
    "    df['authors'] = df['authors'].apply(lambda x: json.loads(x))\n",
    "    df['genres'] = df['genres'].apply(lambda x: json.loads(x))\n",
    "    return df\n",
    "trainset = traite_train_test(trainset)\n",
    "testset = traite_train_test(testset)\n",
    "hehe_test = trainset.copy()\n",
    "df_empty = testset.copy()\n",
    "df_empty['user'] = df_empty['user'].astype('int')\n",
    "df_empty['rating'] = df_empty['rating'].astype('float')\n",
    "df_empty['item'] = df_empty['item'].astype('int')\n",
    "hehe_test.index = range(len(hehe_test))\n",
    "df_empty.index = range(len(df_empty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hehe = pd.concat([hehe_test,df_empty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lr, mlp_factors,gmf_factors, layers, reg, batch_size, num_epochs, train, test):\n",
    "    model = NeuMF(n_users, n_items, mlp_factors,gmf_factors, layers).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=lr,weight_decay=reg)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=10, threshold_mode='abs',threshold = 0.005)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        t1 = time.time()\n",
    "        num_example = len(train)\n",
    "        indices = list(range(num_example))\n",
    "        for i in tqdm(range(0, num_example, batch_size)):\n",
    "            optimizer.zero_grad()\n",
    "            indexs = indices[i:min(i+batch_size, num_example)]\n",
    "            users_index = train.iloc[:, 0].loc[indexs].values\n",
    "            users = torch.LongTensor(users_index).to(DEVICE)\n",
    "            items_index = train.iloc[:, 1].loc[indexs].values\n",
    "            items = torch.LongTensor(items_index).to(DEVICE)\n",
    "            \n",
    "           \n",
    "            rating = torch.FloatTensor(\n",
    "                train.iloc[:, 4].loc[indexs].values).to(DEVICE)\n",
    "            prediction = model(\n",
    "                users, items)\n",
    "\n",
    "            err = loss_func(prediction, rating) \n",
    "            err.backward()\n",
    "            optimizer.step()\n",
    "        t2 = time.time()\n",
    "        #rmse, mae = RMSE(test, model)\n",
    "        \n",
    "        \n",
    "        rmse, mae, p, r, f, accuracy = RMSE(testset,model)\n",
    "        scheduler.step(rmse)\n",
    "        print(\"Learning rate: \", lr, \"Regulation: \", reg,\"Bath_size:\",batch_size)\n",
    "        print(\"RMSE: \", rmse, \"MAE: \", mae)\n",
    "        print(\"Accuracy: \", accuracy, \"Precision: \", p, \"Recall: \", r, \"F1 score: \", f)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = len(hehe['user'].value_counts())\n",
    "n_items = len(hehe['item'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 413/413 [00:09<00:00, 45.24it/s]\n",
      "  1%|          | 5/413 [00:00<00:08, 48.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.002 Regulation:  0.0001 Bath_size: 128\n",
      "RMSE:  tensor(0.9997, grad_fn=<PowBackward0>) MAE:  tensor(0.8067, grad_fn=<L1LossBackward>)\n",
      "Accuracy:  0.8924348089751365 Precision:  0.9224235989990142 Recall:  0.9996712689020382 F1 score:  0.9594951686057976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 413/413 [00:08<00:00, 46.50it/s]\n",
      "  1%|          | 5/413 [00:00<00:08, 48.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.002 Regulation:  0.0001 Bath_size: 128\n",
      "RMSE:  tensor(0.9697, grad_fn=<PowBackward0>) MAE:  tensor(0.7746, grad_fn=<L1LossBackward>)\n",
      "Accuracy:  0.9192692540933899 Precision:  0.9223771983020013 Recall:  1.0 F1 score:  0.959621451104101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 413/413 [00:08<00:00, 47.25it/s]\n",
      "  1%|          | 5/413 [00:00<00:08, 49.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.002 Regulation:  0.0001 Bath_size: 128\n",
      "RMSE:  tensor(0.9622, grad_fn=<PowBackward0>) MAE:  tensor(0.7613, grad_fn=<L1LossBackward>)\n",
      "Accuracy:  0.9201030927835051 Precision:  0.9223771983020013 Recall:  1.0 F1 score:  0.959621451104101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 413/413 [00:08<00:00, 47.71it/s]\n",
      "  1%|          | 5/413 [00:00<00:08, 49.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.002 Regulation:  0.0001 Bath_size: 128\n",
      "RMSE:  tensor(0.9533, grad_fn=<PowBackward0>) MAE:  tensor(0.7523, grad_fn=<L1LossBackward>)\n",
      "Accuracy:  0.9180563978168587 Precision:  0.9223771983020013 Recall:  1.0 F1 score:  0.959621451104101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 413/413 [00:08<00:00, 47.53it/s]\n",
      "  1%|          | 5/413 [00:00<00:08, 47.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.002 Regulation:  0.0001 Bath_size: 128\n",
      "RMSE:  tensor(0.9290, grad_fn=<PowBackward0>) MAE:  tensor(0.7297, grad_fn=<L1LossBackward>)\n",
      "Accuracy:  0.917449969678593 Precision:  0.9235581324382057 Recall:  0.994904667981591 F1 score:  0.9579047317613547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 413/413 [00:08<00:00, 46.58it/s]\n",
      "  1%|          | 5/413 [00:00<00:08, 48.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.002 Regulation:  0.0001 Bath_size: 128\n",
      "RMSE:  tensor(0.9116, grad_fn=<PowBackward0>) MAE:  tensor(0.7112, grad_fn=<L1LossBackward>)\n",
      "Accuracy:  0.9154032747119466 Precision:  0.9273756006820648 Recall:  0.9833168967784353 F1 score:  0.9545273234942163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 413/413 [00:08<00:00, 47.99it/s]\n",
      "  1%|▏         | 6/413 [00:00<00:07, 51.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.002 Regulation:  0.0001 Bath_size: 128\n",
      "RMSE:  tensor(0.9084, grad_fn=<PowBackward0>) MAE:  tensor(0.7075, grad_fn=<L1LossBackward>)\n",
      "Accuracy:  0.9144936325045482 Precision:  0.9304955627110657 Recall:  0.9737015121630507 F1 score:  0.9516083691418015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 413/413 [00:08<00:00, 47.75it/s]\n",
      "  1%|▏         | 6/413 [00:00<00:07, 51.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.002 Regulation:  0.0001 Bath_size: 128\n",
      "RMSE:  tensor(0.9124, grad_fn=<PowBackward0>) MAE:  tensor(0.7107, grad_fn=<L1LossBackward>)\n",
      "Accuracy:  0.9105518496058217 Precision:  0.9327190404321233 Recall:  0.9649901380670611 F1 score:  0.9485801995395242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 413/413 [00:08<00:00, 48.83it/s]\n",
      "  1%|▏         | 6/413 [00:00<00:07, 51.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.002 Regulation:  0.0001 Bath_size: 128\n",
      "RMSE:  tensor(0.9210, grad_fn=<PowBackward0>) MAE:  tensor(0.7185, grad_fn=<L1LossBackward>)\n",
      "Accuracy:  0.9075197089144936 Precision:  0.9338962605548854 Recall:  0.9543885601577909 F1 score:  0.9440312157054018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 413/413 [00:08<00:00, 47.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.002 Regulation:  0.0001 Bath_size: 128\n",
      "RMSE:  tensor(0.9359, grad_fn=<PowBackward0>) MAE:  tensor(0.7313, grad_fn=<L1LossBackward>)\n",
      "Accuracy:  0.9008489993935719 Precision:  0.9354154774524994 Recall:  0.9427186061801447 F1 score:  0.9390528426998486\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "lr = 0.002\n",
    "reg = 1e-4\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "model_neumf = train(lr, mlp_factors,gmf_factors, layers, reg, batch_size, num_epochs, hehe_test,df_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = { 'model': model_neumf.state_dict()}   \n",
    "torch.save(state, 'model_neumf.pkl')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37-caffe-notebook",
   "language": "python",
   "name": "py37-caffe-notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
